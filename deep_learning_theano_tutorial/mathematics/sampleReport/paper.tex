\documentclass{article} % For LaTeX2e
% We will use NIPS submission format
\usepackage{nips13submit_e,times}
% for hyperlinks
\usepackage{hyperref}
\usepackage{url}
% For figures
\usepackage{graphicx} 
\usepackage{subfigure} 
% math packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsopn}
\usepackage{ifthen}
\usepackage{natbib}
\usepackage{dsfont}

\title{Project-I}

\author{
Viviana Petrescu\\
EPFL \\
\texttt{viviana.petrescu@epfl.ch} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\nipsfinalcopy 

\begin{document}

\maketitle


\section{PageRank}

\subsection{Exercise1}
i) After randomly initializing $x0$ and repeating the experiments.
E has the eigenvalues \[ \left( \begin{array}{c}
1\\
 -0.5000 + 0.2887i \\
  -0.5000 - 0.2887i \\
0 \end{array} \right)\]  two real and two complex values,
the largest eigenvalue is 1. The sequence $E^15x0$ normalised using l2 norm, as the number of iterations increases tends to the largest eigenvector of E, the eigenvector corresponding to eigenvalue 1. eigenvector   \[ \left( \begin{array}{c} 
   0.6447\\
    0.2478\\
    0.4154\\
    0.5920\end{array} \right)\] 

ii)   Eigenvector \[ \left( \begin{array}{c}  
	    0.2230\\
    0.3755\\
    0.4201\\
    0.7955\end{array} \right)\] 
    Eigenvalues
  \[ \left( \begin{array}{c}            
  0          \\
   0.5614   \\       
  -0.2807 + 0.2640i\\
  -0.2807 - 0.2640i\end{array} \right)\] 
The largest eigenvalue is 0.5614 and the sequence converges again to the largest eigenvector, up to a constant, -1 in my case.

iii) Eigenvalues of E    
  \[ \left( \begin{array}{c}  
 1.0000          \\
  -0.5000 + 0.2887i\\
  -0.5000 - 0.2887i\\
  -0.0000          \\
   1.0000          \\
  -1.0000   \end{array} \right)\]        
  There are two eigenvalues of 1.
  The sequence after 15 steps does not converge to the largest eigenvector (any of them)
   \[ \left( \begin{array}{c}   
    0.3500\\
    0.1050\\
    0.2099\\
    0.3149\\
    0.6848\\
    0.5043\end{array} \right)\]        



\subsection{Exercise2}
i)  
The igenvectors are
 -0.6446            -0.2887 + 0.5000i  -0.2887 - 0.5000i   0.5345          
  -0.2478            -0.4330 - 0.2500i  -0.4330 + 0.2500i  -0.8018          
  -0.4154             0.5774             0.5774             0.0000          
  -0.5920             0.1443 - 0.2500i   0.1443 + 0.2500i   0.2673          
Eigenvalues are 
   \[ \left( \begin{array}{c}   
   1.0000          \\
  -0.4250 + 0.2454i \\
  -0.4250 - 0.2454i \\
  -0.0000         \end{array} \right)\]         
The convergence vector is 
   \[ \left( \begin{array}{c}   
    0.6447\\
    0.2478\\
    0.4154\\
    0.5920\\
\end{array} \right)\]        


ii) GREEN
   0.2769            -0.3641 - 0.3761i  -0.3641 + 0.3761i   0.0044          
   0.3984             0.5959             0.5959            -0.1091          
   0.4548            -0.3506 + 0.2950i  -0.3506 - 0.2950i  -0.0657          
   0.7468             0.2363 + 0.3242i   0.2363 - 0.3242i   0.9918          
Eigenvalues are 
   \[ \left( \begin{array}{c}   
   0.6618          \\
  -0.2427 + 0.2257i \\
  -0.2427 - 0.2257i \\
  -0.0264     \end{array} \right)\]       
The convergence vector is
   \[ \left( \begin{array}{c}   
    0.2769 \\
    0.3984 \\
    0.4548 \\
    0.7468   \end{array} \right)\]    
    
    
 iii)
BLUE
Eigenvector of M blue
   \[ \left( \begin{array}{c}  
   0.5351        \\
   0.2057           \\
   0.3449             \\       
   0.4914          \\
   0.3943          \\   
   0.3943      \end{array} \right)\] 

The eigenvalues are
   \[ \left( \begin{array}{c}  
   1.0000          \\
   0.8500          \\
  -0.4250 + 0.2454i\\
  -0.4250 - 0.2454i\\
   0.0000          \\
  -0.8500          \end{array} \right)\]    
The convergence vector is
   \[ \left( \begin{array}{c}   
    0.5200\\
    0.2012\\
    0.3358\\
    0.4778\\
    0.4257\\
    0.4085\end{array} \right)\]    
\subsection{Exercise3}
i)
E is a stochastic column matrix for i) and iii). ii) has a column only with 0 elements.
M is a stochastic column matrix for i) and iii) again. ii) has a column only of 0.15 values, so it is not .

ii) Let $A$  be a stochastic column matrix. A and $A^\top$ have the same eigenvalues, so it is enough to show that $A^\top$ has eigenvalue 1, which will imply $A$ also has eigenvalue of 1.

We use the property that for eigenvalue $\lambda$ of $A^\top$
$det(A^\top - \lambda* I) = 0$.
We compute 
\begin{align}
det(A^\top - I) & = \det \begin{pmatrix}
    a_{11} - 1 & a_{21} & ... & a_{n1}\\
    a_{12}    &  a_{22} - 1& ... & a_{n2}\\
    ...& ... & ...& ... \\
    a_{1n} & a_{2n} & ....& a_{nn} - 1
\end{pmatrix}  
\\
det(A^\top - I) & = \det \begin{pmatrix}
    \sum_{i} a_{i1} - 1 & a_{21} & ... & a_{n1}\\
    \sum_{i} a_{i2}  - 1   &  a_{22} - 1& ... & a_{n2}\\
    ...& ... & ...& ... \\
    \sum_{i} a_{in}  - 1& a_{2n} & ....& a_{nn} - 1
   \end{pmatrix}  
 \\
 det(A^\top - I) & = \det \begin{pmatrix}
    0 & a_{21} & ... & a_{n1}\\
    0  &  a_{22} - 1& ... & a_{n2}\\
    ...& ... & ...& ... \\
    0 & a_{2n} & ....& a_{nn} - 1
\end{pmatrix}  
\end{align}
For the first equality we added all the columns $2, 3, ...N-1$ to the first column. For the second equality, the determinant of a matrix with a column of 0 equals 0. This implies $A^\top$ and implicitly A have eigenvalue 1.

Assume that $A$, $A^\top$ have an eigenvalue greater than 1, $\lambda_{0}$ with eigenvector $v$.
$A^\top v = \lambda_{0} v$. Then we have 
$ \sum_{i} a_{it}*v_{i} = \lambda_{0} v_{t}$ for every $t$ in 0..N. Let m be the index corresponding to the largest
entry in v. then $ \sum aik*vi < \sum aij vk = vk <\lambda vk$ 
which is a contradiction, so 1 is the largest eigenvalue.

\subsection{Exercise4}
Gradient of 

$\nabla f = (M-I)^\top\cdot(M-I)\cdot x + \gamma\cdot (\mathds{1}^\top x - 1)\mathds{1} $
\\


$\nabla f = (M-I)^\top\cdot(M-I)\cdot x + \gamma\cdot (\mathds{1} \mathds{1} ^\top)x -\gamma \mathds{1} $
\\
Hessian of f
$\nabla^2 f = (M-I)^\top\cdot(M-I) + \gamma\cdot \mathds{1}\mathds{1} ^\top$



Find the Lipshitx constant..
$\nabla f(x_1) - \nabla f(x_2) =  [ (M-I)^\top\cdot(M-I) + \gamma\cdot (\mathds{1} \mathds{1} ^\top)](x_1 - x_2)$

there is no line here\\
$\| \nabla f(x_1) - \nabla f(x_2) \|=  \| [ (M-I)^\top\cdot(M-I) + \gamma\cdot (\mathds{1} \mathds{1} ^\top)](x_1 - x_2)\|$
\\
$\| \nabla f(x_1) - \nabla f(x_2) \|\leq \| (M-I)^\top\cdot(M-I) + \gamma\cdot (\mathds{1} \mathds{1} ^\top)\| \|x_1 - x_2\| = L \|x_1 - x_2\|$, which 
implies the Lipschitz constant is\\
$L =  \| (M-I)^\top\cdot(M-I) + \gamma\cdot (\mathds{1} \mathds{1} ^\top) \|$



\subsection{Exercise9}
$f_{\sigma} = 0.5\cdot (Mx-x)^\top\cdot(Mx-x) + \gamma\cdot (\mathds{1}^\top x - 1)^2 + 0.5*\sigma* x^\top*x$ 
\\
$\nabla f_{\sigma} = (M-I)^\top\cdot(M-I)\cdot x + \gamma\cdot (\mathds{1}^\top x - 1)\mathds{1} + \sigma\cdot x$ 
\\
$\nabla f_{\sigma} = [(M-I)^\top\cdot(M-I) + \gamma \mathds{1}^\top\cdot \mathds{1} + \sigma I] \cdot x - \gamma\mathds{1}$
\\
$\nabla f_{\sigma} = \phi_{\sigma} \cdot x - \gamma\mathds{1}$


We have $(M-I)^\top\cdot(M-I) $, $\gamma \mathds{1}^\top\cdot \mathds{1}$ and $\sigma I$ are symmetric matrices, which implies
$\phi_{\sigma}$ is symmetric.
 

\subsubsection*{Acknowledgments}

\subsubsection*{References}

\end{document}
